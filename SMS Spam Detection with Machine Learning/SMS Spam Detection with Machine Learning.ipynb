{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e02bdd53",
   "metadata": {},
   "source": [
    "# Spam Detection Project Documentation\n",
    "\n",
    "## Introduction:\n",
    "This project aims to develop a machine learning model for spam detection in emails. Leveraging techniques from natural language processing (NLP) and supervised learning, we build a robust system capable of accurately identifying spam emails, thereby enhancing email security and user experience.\n",
    "\n",
    "## Project Overview:\n",
    "\n",
    "### 1. Data Loading and Overview:\n",
    "- Imported the pandas library for data manipulation and analysis.\n",
    "- Loaded the dataset from a CSV file using pandas, handling encoding issues.\n",
    "- Displayed the structure and initial rows of the dataset to understand its format.\n",
    "\n",
    "### 2. Data Cleaning and Preparation:\n",
    "- Dropped unnecessary columns ('Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4') from the dataset.\n",
    "- Renamed columns for clarity ('v1' to 'label', 'v2' to 'message').\n",
    "- Checked for missing values and found none.\n",
    "\n",
    "### 3. Text Preprocessing:\n",
    "- Imported necessary libraries for text preprocessing, including NLTK.\n",
    "- Lowercased all text messages for consistency.\n",
    "- Removed punctuation and tokenized messages into individual words.\n",
    "- Removed stopwords and applied stemming to reduce words to their root forms.\n",
    "\n",
    "### 4. Feature Extraction:\n",
    "- Used TF-IDF vectorization to convert text data into numerical features.\n",
    "- Converted tokenized messages back to string format for vectorization.\n",
    "- Created TF-IDF matrix representing messages and unique words.\n",
    "- Transformed the target variable 'label' into binary format (spam: 1, ham: 0).\n",
    "\n",
    "### 5. Model Training:\n",
    "- Split the dataset into training and testing sets (80% train, 20% test).\n",
    "- Initialized and trained a Multinomial Naive Bayes classifier on the training data.\n",
    "- Evaluated the classifier's performance on the testing set, achieving an accuracy of 96.14%.\n",
    "\n",
    "### 6. Model Evaluation:\n",
    "- Generated a classification report to assess precision, recall, and F1-score.\n",
    "- Achieved high precision and recall for non-spam (ham) messages, but lower recall for spam messages.\n",
    "\n",
    "### 7. Parameter Tuning:\n",
    "- Utilized GridSearchCV to tune the hyperparameter 'alpha' for the Naive Bayes classifier.\n",
    "- Found the best alpha value to be 0.1 through cross-validation.\n",
    "\n",
    "### 8. Final Model Evaluation:\n",
    "- Trained a new classifier with the best alpha value obtained.\n",
    "- Evaluated the tuned classifier's performance, achieving an accuracy of 98.48%.\n",
    "- Demonstrated high precision and recall for both spam and non-spam messages.\n",
    "\n",
    "## Conclusion:\n",
    "Through a systematic approach encompassing data preprocessing, feature extraction, model training, and evaluation, we have successfully developed a robust spam detection system. The final model demonstrates high accuracy and performs effectively in distinguishing between spam and non-spam emails. Future work may involve exploring additional feature engineering techniques and advanced machine learning models for further improving performance.\n",
    "\n",
    "## Scores:\n",
    "\n",
    "- **Accuracy (Before Tuning):** 96.14%\n",
    "- **Accuracy (After Tuning):** 98.48%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2635e09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the pandas library for data manipulation and analysis.\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the dataset and load it into a pandas DataFrame.\n",
    "# We use 'latin1' encoding as the default 'utf-8' encoding was not successful.\n",
    "# This can be common with datasets that contain characters outside the 'utf-8' range.\n",
    "spam_data_path = 'spam.csv'\n",
    "spam_data = pd.read_csv(spam_data_path, encoding='latin1')\n",
    "\n",
    "# Displaying the first few rows of the DataFrame to understand its structure.\n",
    "# We expect to see a label column ('v1') that indicates if the message is 'spam' or 'ham' (non-spam),\n",
    "# and a text column ('v2') which contains the email message itself.\n",
    "spam_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7f12c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  label                                            message\n",
       " 0   ham  Go until jurong point, crazy.. Available only ...\n",
       " 1   ham                      Ok lar... Joking wif u oni...\n",
       " 2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       " 3   ham  U dun say so early hor... U c already then say...\n",
       " 4   ham  Nah I don't think he goes to usf, he lives aro...,\n",
       " label      0\n",
       " message    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Cleaning and Preparation\n",
    "\n",
    "# Dropping unnecessary columns that are not needed for spam detection.\n",
    "# These are the columns named 'Unnamed: 2', 'Unnamed: 3', and 'Unnamed: 4'.\n",
    "spam_data = spam_data.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'])\n",
    "\n",
    "# Renaming the columns for better readability and accessibility.\n",
    "# 'v1' will be renamed to 'label' and 'v2' to 'message'.\n",
    "spam_data.columns = ['label', 'message']\n",
    "\n",
    "# Checking for any missing values in our dataset.\n",
    "# Missing values need to be handled appropriately before training a machine learning model.\n",
    "missing_values = spam_data.isnull().sum()\n",
    "\n",
    "# Display the new structure of the DataFrame and the count of missing values.\n",
    "spam_data.head(), missing_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "611dcd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  [go, jurong, point, crazi, avail, bugi, n, gre...\n",
       "1   ham                       [ok, lar, joke, wif, u, oni]\n",
       "2  spam  [free, entri, 2, wkli, comp, win, fa, cup, fin...\n",
       "3   ham      [u, dun, say, earli, hor, u, c, alreadi, say]\n",
       "4   ham  [nah, dont, think, goe, usf, live, around, tho..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Preprocessing\n",
    "\n",
    "# Importing the necessary libraries for text preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import string\n",
    "\n",
    "# Downloading the set of stopwords from NLTK\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Convert all messages to lower case\n",
    "spam_data['message'] = spam_data['message'].str.lower()\n",
    "\n",
    "# Remove punctuation from messages\n",
    "spam_data['message'] = spam_data['message'].apply(lambda x: ''.join([letter for letter in x if letter not in string.punctuation]))\n",
    "\n",
    "# Tokenizing the messages into individual words\n",
    "spam_data['message'] = spam_data['message'].apply(nltk.word_tokenize)\n",
    "\n",
    "# Removing stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "spam_data['message'] = spam_data['message'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "# Applying stemming\n",
    "stemmer = SnowballStemmer('english')\n",
    "spam_data['message'] = spam_data['message'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "\n",
    "# Display the processed messages\n",
    "spam_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a533dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5572, 8033), (5572,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Extraction\n",
    "\n",
    "# Importing TfidfVectorizer from sklearn.feature_extraction.text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# We need to convert the list of words back into string format to use TfidfVectorizer\n",
    "spam_data['message'] = spam_data['message'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Creating a TfidfVectorizer object\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "\n",
    "# Fitting the vectorizer to the messages and transforming the messages into a numeric format\n",
    "X = tfidf_vect.fit_transform(spam_data['message'])\n",
    "\n",
    "# Getting the target variable 'label' where spam is 1 and ham is 0\n",
    "y = spam_data['label'].apply(lambda x: 1 if x == 'spam' else 0)\n",
    "\n",
    "# Display the shape of the features matrix X and target vector y\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2a6fb86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9614349775784753"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Training\n",
    "\n",
    "# Importing the Multinomial Naive Bayes model from scikit-learn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Importing train_test_split to split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a Multinomial Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Training the classifier on the training set\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluating the classifier on the testing set\n",
    "accuracy = nb_classifier.score(X_test, y_test)\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe017e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       965\n",
      "           1       1.00      0.71      0.83       150\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.98      0.86      0.91      1115\n",
      "weighted avg       0.96      0.96      0.96      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "# Importing classification_report from scikit-learn to compute evaluation metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Making predictions on the testing set\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Computing and printing the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d5584aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9847533632286996"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Training with Parameter Tuning\n",
    "\n",
    "# Importing GridSearchCV for parameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Defining a range of alpha values to try\n",
    "alpha_values = {'alpha': [0.1, 0.5, 1.0, 2.0, 5.0, 10.0]}\n",
    "\n",
    "# Creating a Multinomial Naive Bayes classifier\n",
    "nb_classifier_tuned = MultinomialNB()\n",
    "\n",
    "# GridSearchCV for parameter tuning\n",
    "grid_search = GridSearchCV(nb_classifier_tuned, param_grid=alpha_values, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fitting the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Extracting the best alpha value from the grid search results\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "# Creating a new Naive Bayes classifier with the best alpha value\n",
    "nb_classifier_best = MultinomialNB(alpha=best_alpha)\n",
    "\n",
    "# Training the classifier on the training set\n",
    "nb_classifier_best.fit(X_train, y_train)\n",
    "\n",
    "# Evaluating the classifier on the testing set\n",
    "accuracy_best = nb_classifier_best.score(X_test, y_test)\n",
    "accuracy_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "647cd105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       965\n",
      "           1       0.97      0.92      0.94       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.96      0.97      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation with Best Parameters\n",
    "\n",
    "# Making predictions on the testing set using the classifier with the best alpha value\n",
    "y_pred_best = nb_classifier_best.predict(X_test)\n",
    "\n",
    "# Computing and printing the classification report for the classifier with the best alpha value\n",
    "report_best = classification_report(y_test, y_pred_best)\n",
    "print(report_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980d46ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
